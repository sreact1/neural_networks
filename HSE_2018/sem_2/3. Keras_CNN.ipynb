{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Наша n-ая свёрточная нейросеть \n",
    "\n",
    "Пришло время построить нашу первую свёрточную нейросеть. Будем использовать для этого датасет [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html) (Canadian Institute for Advanced Research). Он включает в себя картинки из 10 разных классов: самолёты, машины, птицы, кошки, олени, собаки, лягушки, лошади, корабли, грузовики.   \n",
    "\n",
    "<img src=\"http://www.pvsm.ru/images/2016/11/18/optimizaciya-neirosetevoi-platformy-Caffe-dlya-arhitektury-Intel-3.png\" style=\"width:50%\">\n",
    "\n",
    "Всего $60 000$ цветных картинок размера $32 \\times 32$. В каждом из классов ровно по $6000$ картинок.  Есть расширение этого датасета, CIFAR_100. Думаю, что по названию вы догадались, что в нём сто видов картинок. Попробовать обуздать этот датасет можно, подгрузив его следущими командами: \n",
    "\n",
    "```from keras.datasets import cifar100\n",
    "   (x_train, y_train), (x_test, y_test) = cifar100.load_data(label_mode='fine')```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# подгружаем пакеты\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Скачиваем и готовим данные\n",
    "\n",
    "Приготовьте на своём компухтере местечко для датасета. Он достаточно громоздкий и включает 60 000 картинок. Кстати говоря, если очень хочется, можете принять участие [в стареньком соревновании на Kagle,](https://www.kaggle.com/c/cifar-10) связанным с этим датасетом. Там же на форуме можно найти интересный код. :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train samples:\", x_train.shape, y_train.shape)\n",
    "print(\"Test samples:\", x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Помним, что у нас всего 10 классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10\n",
    "cifar10_classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \n",
    "                   \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нарисуем несколько рандомных картинок из тренировочной выборки. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код здесь "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отлично! Как вы помните, если пронормаровать данные, то сетка будет сходиться на порядок быстрее. \n",
    "\n",
    "Также, как вы помните из предыдущих скриптов, картинка - это тензор из циферок. Каждая циферка сообщает нам о яркости конкретного пикселя. Яркость измеряется по шкале от 0 до 255. В связи с этим фактом, нормализация будет немного странной: \n",
    "\n",
    "$$\n",
    "x_{norm} = \\frac{x}{255}\n",
    "$$\n",
    "\n",
    "Также мы помним, что классы нужно конвертировать одним горячи кодированием (one-hot encoding) в набор из дамми-переменных. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# делай раз\n",
    "\n",
    "# ващ код \n",
    "\n",
    "# делай два! \n",
    "\n",
    "# ваш код "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  Выбираем для нашей нейросети архитектуру\n",
    "\n",
    "Свёрточная нейронная сеть строится из нескольких разных типов слоёв: \n",
    "\n",
    "* [Conv2D](https://keras.io/layers/convolutional/#conv2d) - Конволюция:\n",
    "    - **filters**: число выходных каналов; \n",
    "    - **kernel_size**: размер окна для свёртки;\n",
    "    - **padding**: padding=\"same\" добавляет нулевую каёмку по краям картинки, чтбы после свёртки размеры картинки не изменялись; padding='valid' ничего не добавляет;\n",
    "    - **activation**: \"relu\", \"tanh\", etc.\n",
    "    - **input_shape**: размер входа\n",
    "* [MaxPooling2D](https://keras.io/layers/pooling/#maxpooling2d) - макспулинг\n",
    "* [Flatten](https://keras.io/layers/core/#flatten) - разворачивает картинку в вектор \n",
    "* [Dense](https://keras.io/layers/core/#dense) - полносвязный слой (fully-connected layer)\n",
    "* [Activation](https://keras.io/layers/core/#activation) - функция активации\n",
    "* [LeakyReLU](https://keras.io/layers/advanced-activations/#leakyrelu) - leaky relu активация\n",
    "* [Dropout](https://keras.io/layers/core/#dropout) - дропаут.\n",
    "\n",
    "\n",
    "В модели, которую мы определим ниже, на вход будет идти тензоры размера __(None, 32, 32, 3)__ и __(None, 10)__. На выходе мы будем получать вероятноть того, что объект относится к конкретному классу. Разменость __None__ заготовлена для размерности батча. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# подгружаем важные строительные блоки\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, InputLayer\n",
    "from keras.layers.advanced_activations import LeakyReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соберите сетку со следующей архитектурой: \n",
    "\n",
    "* Четыре свёрточных слоя с ядром $3 \\times 3$ и числом фильтров $16, 32, 32, 64$. Используйте same padding. \n",
    "* Слой пулинга размера $2 \\times 2$. после каждыйх двух свёрточных слоёв. \n",
    "* В качестве функции активации используйте LeakyReLU с параметром $0.1$. Используйте её после каждого слоя. \n",
    "* Разверните сеть в полносвязную, добавьте слой с $256$ нейронами.\n",
    "* На выходе используйте __Softmax__\n",
    "* После полносвязного слоя добавьте __Dropout__ с вероятностью $0.5$, после каждого макспулинга добавьте __Dropout__ с вероятностью $0.25$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    \"\"\"\n",
    "    Определите архитектуру свой сетки внутри этой функции\n",
    "    \"\"\"\n",
    "\n",
    "    # ваш код \n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Взглянем на нашу модель\n",
    "model = make_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Огромное количество параметров нам предстоит оценить. \n",
    "\n",
    "## 3. Оцениваем модель\n",
    "\n",
    "Обучение модели может занять примерно 4-8 минут на каждой эпохе. В случае, если на картинке качество модели не будет расти, придётся переопределять параметры вроде скорости обучения. Если и это не поможет, придётся думать о новой архитектуре. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_LR = 5e-3    # Скорость обучения \n",
    "BATCH_SIZE = 32   # Размер батча\n",
    "EPOCHS = 10       # Эпохи \n",
    "\n",
    "model = make_model()  # Создаём модель \n",
    "\n",
    "# Выбираем для модели оптимизатор и собираем её\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',  # Кросс энтропия обычно используется как функция потерь для \n",
    "                                      # задачи многоклассовой классификации\n",
    "    optimizer=keras.optimizers.adamax(lr=INIT_LR),  # SGD наш оптимизатор \n",
    "    metrics=['accuracy']  # Будем в ходе обучения запоминать точность прогнозов\n",
    ")\n",
    "\n",
    "# Новая фишка! Функция, которая корректирует скорость обучения каждую эпоху \n",
    "def lr_scheduler(epoch):\n",
    "    return INIT_LR * 0.9 ** epoch\n",
    "\n",
    "# Мы готовы к обучению \n",
    "history = model.fit(\n",
    "    x_train2, y_train2,    # Данные\n",
    "    batch_size=BATCH_SIZE, # Сколько сетка кушает за раз \n",
    "    epochs=EPOCHS,         # Сколько полных проходов по данным\n",
    "    # Колбэки. Через них реализован всякий полезный функционал. В прошлый раз мы \n",
    "    # с помощью этого параметра делали early stopping \n",
    "    callbacks=[keras.callbacks.LearningRateScheduler(lr_scheduler)],\n",
    "    validation_data=(x_test2, y_test2),  # Немножко валидации :) \n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраняем веса модели в файл ибо модель училась долго \n",
    "model.save_weights(\"cifar_10_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Можем подгрузить веса назад, если случилась беда и комп отрубило \n",
    "model = make_model()\n",
    "model.load_weights(\"cifar_10_weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим как проходил процесс обучения и какого качества нам удалось добиться. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "plt.plot(history.history['loss'][start:])\n",
    "plt.plot(history.history['val_loss'][start:])\n",
    "plt.legend(['Train loss', 'Validation loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = model.predict_proba(x_test2)\n",
    "y_pred_test_classes = np.argmax(y_pred_test, axis=1)\n",
    "y_pred_test_max_probas = np.max(y_pred_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix and accuracy\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "plt.figure(figsize=(7, 6))\n",
    "plt.title('Confusion matrix', fontsize=16)\n",
    "plt.imshow(confusion_matrix(y_test, y_pred_test_classes))\n",
    "plt.xticks(np.arange(10), cifar10_classes, rotation=45, fontsize=12)\n",
    "plt.yticks(np.arange(10), cifar10_classes, fontsize=12)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "print(\"Test accuracy:\", accuracy_score(y_test, y_pred_test_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хммм... 80% это неплохо. Судя по матрице, модель не совершает каких-то систематических ошибок в одном из конкретных классов. Например, она не путает лошадей с оленями. Попробуем сделать пару предсказаний и посмотреть на картинки. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = 8\n",
    "rows = 2\n",
    "fig = plt.figure(figsize=(2 * cols - 1, 3 * rows - 1))\n",
    "for i in range(cols):\n",
    "    for j in range(rows):\n",
    "        random_index = np.random.randint(0, len(y_test))    # Выбираем рандомный объект из теста \n",
    "        ax = fig.add_subplot(rows, cols, i * rows + j + 1)  # выделяем место для картинки \n",
    "        ax.grid('off')                                      # октлючаем решётку \n",
    "        ax.axis('off')                                      # отключаем оси \n",
    "        ax.imshow(x_test[random_index, :])                  # рисуем картинку \n",
    "        pred_label = cifar10_classes[y_pred_test_classes[random_index]]  # истиный класс\n",
    "        pred_proba = y_pred_test_max_probas[random_index]                # вероятность \n",
    "        true_label = cifar10_classes[y_test[random_index, 0]]            # предсказанный класс\n",
    "        ax.set_title(\"pred: {}\\nscore: {:.3}\\ntrue: {}\".format(\n",
    "               pred_label, pred_proba, true_label    # Подписываем картинки \n",
    "        ))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data augmentation\n",
    "\n",
    "Попробуем обучить ту же модель, но искуственно расширяя набор данных за счёт [случайных искажений.](https://machinelearningmastery.com/image-augmentation-deep-learning-keras/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `rotation_range`  значение в градусах (0-180), диапазон, в пределах которого произвольно вращаются изображения;\n",
    "* `width_shift` и `height_shift` это диапазоны (в долях от общей ширины или высоты), в пределах которых можно произвольно переводить изображения по вертикали или горизонтали;\n",
    "* `rescale` это коэффициент скалирования, на который мы умножаем наши данные перед каждой модернизацией;\n",
    "* `shear_range` диапазон для рандомных сдвигов\n",
    "* `zoom_range` для случайного масштабирования внутри фотографий\n",
    "* `horizontal_flip` для переворачивания половины изображения по горизонтали\n",
    "* `fill_mode` стратегия для заполнения вновь появившихся пикселей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=0,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        rescale=255,\n",
    "        shear_range=0,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen.fit(x_train2)  # зафитим генератор "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = datagen.flow(x_train2, y_train2, batch_size=15) # итератор по данным из выборки\n",
    "\n",
    "images, categories = it.next()\n",
    "print(\"Number of images returned by iterator:\", len(images))\n",
    "\n",
    "# преобразуем часть картинок и посмотрим как они теперь выглядят \n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "for i in range(15):\n",
    "    plt.subplot(3, 5, i+1)\n",
    "    im = images[i]\n",
    "    c = np.where(categories[i] == 1)[0][0] # convert one-hot to regular index\n",
    "    plt.imshow(im)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим как наша аугментация сказывается на какой-то одной конкретной картинке \n",
    "it = datagen.flow(np.array(15*[x_train2[200]]),np.array(15*[y_train2[200]]), batch_size=15) # итератор \n",
    "\n",
    "images, categories = it.next()\n",
    "print(\"Number of images returned by iterator:\", len(images))\n",
    "\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "for i in range(15):\n",
    "    plt.subplot(3, 5, i+1)\n",
    "    im = images[i]\n",
    "    c = np.where(categories[i] == 1)[0][0] # convert one-hot to regular index\n",
    "    plt.imshow(im)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Собираем вместе с нашим генератором нейронку. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  make_model()\n",
    "  \n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "datagen.fit(x_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# учим модель на сгенерированных батчах \n",
    "dgen = imdgen.flow(x_train2, y_train2, batch_size=32)\n",
    "\n",
    "# при каждой эпохе картинка искажается по-новому и попадает на вход в нашу сетку\n",
    "hist = model.fit_generator(\n",
    "    dgen,\n",
    "    samples_per_epoch = x_train2.shape[0],\n",
    "    nb_epoch = 5,\n",
    "    validation_data=(x_test2, y_test2),\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посмотрите насколько сильно удалось улучшить качество модели\n",
    "\n",
    "# Ваш код "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
