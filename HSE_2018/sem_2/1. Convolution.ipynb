{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Свёртка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Информация, которую можно было бы использовать в моделях, бывает очень разной. Например, в модель спокойно можно добавить фичи, созданные на основе фоток. Обычно это делается с помощью нейронок. Именно этим мы и займёмся. Однако для начала давайте немного поработаем с фотками. \n",
    "\n",
    "Для работы с фото мы будем использовать пакет `cv2`. Для его установки нужно прописать в консоли `pip3 install opencv-python`.  Для него написана довольно хорошая и понятная [документация.](http://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_gui/py_image_display/py_image_display.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np     # Пакет для работы с векторами и матрицами\n",
    "import urllib          # Пакет для чтения ссылок\n",
    "   \n",
    "import cv2 # Пакет для работы с фоточками \n",
    "\n",
    "from matplotlib import pyplot as plt  # Графики \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Слово о тензорах и картинках\n",
    "\n",
    "Подгрузим какую-нибудь фотографию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем картинку\n",
    "# 0 - подгрузка матрицы яркостей\n",
    "# 1 - подгрузка матрицы из RGB-троек\n",
    "\n",
    "def url_to_image(url):\n",
    "    resp = urllib.request.urlopen(url)                        # Открываем фото\n",
    "    image = np.asarray(bytearray(resp.read()), dtype=\"uint8\") # Распаковываем его в матрицу\n",
    "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)             # Конвертируем в формат для нашего пакета   \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)            # Выбираем нужную цветовую схему \n",
    "    return image\n",
    "\n",
    "# Загружаем фотку и смотрим как она выглядит \n",
    "img = url_to_image('https://www.mirf.ru/wp-content/uploads/2017/01/Drakarys.jpg')\n",
    "\n",
    "plt.figure(figsize = (12,8))\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отлично, фото в наших руках. На самом деле каждая картинка это набор пикселей. Если мы попросим питон показать нам картинку, он покажет матрицу из чисел.  Каждому пикселю в этой матрице соответствует число. Это число сообщает нам о том насколько этот пиксель яркий. Яркость измеряется по шкале от $0$ до $255$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img[0][:5]  # цвета верхник пикселей по шкале RGB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Цветные картинки представляются в виде [тензора,](https://www.wikiwand.com/ru/%D0%A2%D0%B5%D0%BD%D0%B7%D0%BE%D1%80) то есть матрицы из матриц. Любой цвет можно получить, смешав в какой-то пропорции красный, зелёный и синий цвета. В связи с этим каждый пиксель обычно характеризуют тремя цифрами: (насколько пиксель красный, насколько пиксель зелёный, насколько пиксель синий). Такой формат хранения картинки называется [RGB-форматом.](https://www.wikiwand.com/ru/RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Видим, что у нас картинка размера 87 на 130 пикселей и описывается 3 матрицами (одна на каждый цвет)\n",
    "img.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Все действия по редактированию картинки сводятся к математике. Чтобы осветлить картинку, нужно прибавить к каждому пикселю какое-то число. Для этого используют функцию `cv2.add`. В случае прибавления очень большого числа, она накопит яркость 255 и не пробьёт этот порог. Мы добвим 30 пунктов только к красной координате. Если захочется добавить 30 пунктов ко всем трём координатам, rкод придётся немнго модернизировать. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_1 = cv2.add(img,30)\n",
    "\n",
    "plt.figure(figsize = (12,8))\n",
    "plt.imshow(img_1)\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Умножение каждого пикселя на какое-то число увеличит контраст. Также проделаем этот фокус только с красной координатой. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_1 = cv2.multiply(img,0.5) # повышаем контраст\n",
    "\n",
    "plt.figure(figsize = (12,8))\n",
    "plt.imshow(img_1)\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно посмотреть на то как распределены на картинке пиксели различной яркости."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = ('b','g','r')\n",
    "for i,col in enumerate(color):\n",
    "    histr = cv2.calcHist([img],[i],None,[256],[0,256])\n",
    "    plt.plot(histr,color = col)\n",
    "    plt.xlim([0,256])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Эквилизация гистограммы\n",
    "\n",
    "Изобразим гистограмму картинки и эмпирическую функцию распределения яркости пикселя.\n",
    "\n",
    "Наши пиксели, на представленной ниже картинке сосредочены по своей яркости на определённом промежутке. Из-за этого мы не можем чётко выделить объекты на картинке. Если мы растянем пиксели по яркости в разные углы интервала, объекты начнут выделяться более чётко. В этом состоит смысл эквилизации. В ходе этого растягивания эмпирическая функция распределеия станет прямой. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('forest.jpg',0)\n",
    "\n",
    "plt.figure(figsize = (12,8))\n",
    "plt.imshow(img,cmap='gray')\n",
    "plt.xticks([]), plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist,bins = np.histogram(img.flatten(),256,[0,256])\n",
    "\n",
    "cdf = hist.cumsum()\n",
    "cdf_normalized = cdf * hist.max()/ cdf.max()\n",
    "\n",
    "plt.plot(cdf_normalized, color = 'b')\n",
    "plt.hist(img.flatten(),256,[0,256], color = 'r')\n",
    "plt.xlim([0,256])\n",
    "plt.legend(('cdf','histogram'), loc = 'upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прделаем эквилизацию. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf_m = np.ma.masked_equal(cdf,0)\n",
    "cdf_m = (cdf_m - cdf_m.min())*255/(cdf_m.max()-cdf_m.min())\n",
    "cdf = np.ma.filled(cdf_m,0).astype('uint8')\n",
    "\n",
    "img2 = cdf[img]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,8))\n",
    "plt.imshow(img2,cmap='gray')\n",
    "plt.xticks([]), plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist,bins = np.histogram(img2.flatten(),256,[0,256])\n",
    "\n",
    "cdf = hist.cumsum()\n",
    "cdf_normalized = cdf * hist.max()/ cdf.max()\n",
    "\n",
    "plt.plot(cdf_normalized, color = 'b')\n",
    "plt.hist(img2.flatten(),256,[0,256], color = 'r')\n",
    "plt.xlim([0,256])\n",
    "plt.legend(('cdf','histogram'), loc = 'upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Контраст на изображении стал виден более чётко. Гистограмма растянулась по яркости на весь диапозон. Внутри пакета есть более удобная для эквилизации функция."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,15))\n",
    "\n",
    "img2 = cv2.equalizeHist(img) # эквилизация гистограммы\n",
    "\n",
    "plt.subplot(121),plt.imshow(img,cmap='gray'),plt.title('Before')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(img2,cmap='gray'),plt.title('After')\n",
    "plt.xticks([]), plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Свёртка\n",
    "\n",
    "Свёртка это операция, которая превращает набор одних пикселей в другие. Обычно она осущствляется с помощью ядра свёртки, матрицы произвольного размера (обычно 3х3). Центральный элемент такой матрицы называется якорем свёртки. Он применяется к центральному пикселю. \n",
    "\n",
    "Работает свёртка очень просто. При вычислении нового значения выбранного пикселя изображения, ядро свёртки прикладывается своим центром к этому пикселю. Далее, вычисляется сумма произведений значений пикселей изображения на значения, накрывшего данный пиксель элемента ядра. Полученная сумма и является новым значением выбранного пикселя.\n",
    "\n",
    "\n",
    "<center>\n",
    "<img src=\"./convolution_schematic.gif\">\n",
    "</center>\n",
    "\n",
    "Используя матрицы с разными коэффициентами можно получать раные эффекты. \n",
    "\n",
    "Попробуем ухудшить качество изображения. В этом нам поможет следующее ядро размера 3 на 3.\n",
    "\n",
    "$$ K = \\frac{1}{9} \\cdot \\begin{pmatrix}\n",
    "1 & 1 & 1  \\\\\n",
    "1 & 1 & 1  \\\\         \n",
    "1 & 1 & 1 \n",
    "\\end{pmatrix} $$\n",
    "\n",
    "Оно берёт пиксель в каждом квадрате размера 3 на 3 и заменяет его на арифмитическое среднее всех пикселей. Таким образом размерность картинки и её качество падают."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,12))\n",
    "\n",
    "kernel = np.ones((5,5),np.float32)/25  # Создали в нумпай матрицу из 1/25 размера 5 на 5\n",
    "dst = cv2.filter2D(img,-1,kernel)      # применили матрицу к нашей картинке \n",
    "\n",
    "plt.subplot(121),plt.imshow(img,),plt.title('Original')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(dst),plt.title('Corrected')\n",
    "plt.xticks([]), plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем применить другие ядра. Например, ядро для сглаживания.\n",
    "\n",
    "$$ \\begin{pmatrix}\n",
    "0.1 & 0.1 & 0.1  \\\\\n",
    "0.1 & 0.1 & 0.1 \\\\         \n",
    "0.1 & 0.1 & 0.1 \n",
    "\\end{pmatrix} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,12))\n",
    "\n",
    "kernel = 0.1*np.ones((8,8),np.float32)\n",
    "dst = cv2.filter2D(img,-1,kernel)\n",
    "\n",
    "plt.subplot(121),plt.imshow(img,),plt.title('Original')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(dst),plt.title('Corrected')\n",
    "plt.xticks([]), plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ядро для увеличения чёткости. Обратите внимание на большое значение якоря.\n",
    "\n",
    "$$ \\begin{pmatrix}\n",
    "0.1 & 0.1 & 0.1  \\\\\n",
    "0.1 & 2 & 0.1 \\\\         \n",
    "0.1 & 0.1 & 0.1 \n",
    "\\end{pmatrix} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,12))\n",
    "\n",
    "kernel = -0.1*np.ones((3,3),np.float32)\n",
    "kernel[1,1]=2\n",
    "dst = cv2.filter2D(img,-1,kernel)\n",
    "\n",
    "plt.subplot(121),plt.imshow(img,),plt.title('Original')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(dst),plt.title('Corrected')\n",
    "plt.xticks([]), plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Забавно, что при повторном применении фильтра для увеличения чёткости, картинка покрывается шумом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,12))\n",
    "\n",
    "kernel = -0.1*np.ones((3,3),np.float32)\n",
    "kernel[1,1]=2\n",
    "dst = cv2.filter2D(img,-1,kernel)\n",
    "# Повторяем повторно фильтр 2 раза \n",
    "for i in range(20):\n",
    "    dst = cv2.filter2D(dst,-1,kernel)\n",
    "\n",
    "plt.subplot(121),plt.imshow(img,),plt.title('Original')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(dst),plt.title('Corrected')\n",
    "plt.xticks([]), plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Гауссовский фильтр хорошо удаляет шум.  Чуствуете иронию? Нормальное распределение пригождается фотошоперам в жизни на ежедневной основе! Правда они даже не знают об этом..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,12))\n",
    "\n",
    "blur_0 = cv2.GaussianBlur(dst,(5,5),0)\n",
    "plt.subplot(121),plt.imshow(dst),plt.title('Original')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(blur_0),plt.title('Corrected')\n",
    "plt.xticks([]), plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ядра бывают очень разными. Например, вы можете попробовать использовать следующие: \n",
    "\n",
    "* Ядро для увеличения яркости. \n",
    "\n",
    "$$ \\begin{pmatrix}\n",
    "-0.1 & 0.2 & -0.1  \\\\\n",
    "0.2 & 3 & 0.2 \\\\         \n",
    "-0.1 & 0.2 & -0.1 \n",
    "\\end{pmatrix} $$\n",
    "\n",
    "* Ядро для затемнения. \n",
    "\n",
    "$$ \\begin{pmatrix}\n",
    "-0.1 & 0.1 & -0.1  \\\\\n",
    " 0.1 & 0.5 & 0.1 \\\\         \n",
    "-0.1 & 0.1 & -0.1 \n",
    "\\end{pmatrix} $$\n",
    "\n",
    "* Ядро, которое ничего не делает \n",
    "\n",
    "$$ \\begin{pmatrix}\n",
    "0 & 0 & 0  \\\\\n",
    "0 & 1 & 0 \\\\         \n",
    "0 & 0 & 0 \n",
    "\\end{pmatrix} $$\n",
    "\n",
    "* Ядро, которое сдвигает картинку\n",
    "\n",
    "$$ \\begin{pmatrix}\n",
    "1 & 0 & 100  \\\\\n",
    "0 & 1 & 50     \n",
    "\\end{pmatrix} $$\n",
    "\n",
    "* Ядро для пофорота картинки на угол $\\phi$ \n",
    "\n",
    "$$ \\begin{pmatrix}\n",
    "\\cos\\phi & -sin\\phi  \\\\\n",
    "\\sin\\phi & \\cos\\phi\n",
    "\\end{pmatrix} $$\n",
    "\n",
    "* Эрозия и наращивание. Выбираем пиксель с максимальной или минимальной интенсивностью из окрестности.  Наращиваение приводит к увеличению ярких объектов, а эрозия к увеличению тёмных. Наращивание может быть использовано для увеличения бликов ярких изображений. Обычно эрозия имеет округлую форму и выглядит, например, так:\n",
    "\n",
    "$$ \\begin{pmatrix}\n",
    "0 & 0 & 1 & 0 & 0  \\\\\n",
    "0 & 1 & 1 & 1 & 0  \\\\         \n",
    "1 & 1 & 1 & 1 & 1  \\\\\n",
    "0 & 1 & 1 & 1 & 0  \\\\        \n",
    "0 & 0 & 1 & 0 & 0\n",
    "\\end{pmatrix} $$\n",
    "\n",
    "\n",
    "Абсолютно любая матрица задаёт какое-то преобразование линейного пространства. В данном случае нашей фотографии. При хорошем знании линала, вы можете придумать самые безумные ядра. Попробуйте! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код для игры в фильры "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Углубляемся в свёртку\n",
    "\n",
    "Попробуйте угадать, что делают следующие два фильтра. \n",
    "\n",
    "$$ \\begin{pmatrix}\n",
    "-1 & -1 & -1  \\\\\n",
    "0 & 0 & 0 \\\\         \n",
    "1 & 1 & 1 \n",
    "\\end{pmatrix}  $$\n",
    "\n",
    "$$ \\begin{pmatrix}\n",
    "-1 & 0 & 1  \\\\\n",
    "-1 & 0 & 1 \\\\         \n",
    "-1 & 0 & 1 \n",
    "\\end{pmatrix} $$\n",
    "\n",
    "Внимание, ответ. Первый фильтр пытается понять насколько резко изменяется яркость картинки по вертикали и находит вертикальные границы. Второй фильтр пытается понять насколько резко изменяется картинка по горизонтали и находит горизонтальные границы. Если просуммировать применение этих фильтров, можно получить чёткое очертание границ картинки. Чем больше в матрицах цифры, тем более резкую разницу находят ядра. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "kernel1 = np.array([[-1,-1,-1],[0,0,0],[1,1,1]],np.float32)\n",
    "kernel2 = kernel1.T\n",
    "\n",
    "dst1 = cv2.filter2D(img,-1,kernel1)\n",
    "dst2 = cv2.filter2D(img,-1,kernel2)\n",
    "gr1 = cv2.add(dst1,dst2)\n",
    "\n",
    "plt.subplot(131),plt.imshow(dst1),plt.title('Vertical')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(132),plt.imshow(gr1),plt.title('All')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(133),plt.imshow(dst2),plt.title('Horisontal')\n",
    "plt.xticks([]), plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если сначала обработать картинку ядром для повышения чёткости, а после применить фильр для поиска границ, они детектируются более чётко. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "\n",
    "kernel = -0.1*np.ones((3,3),np.float32)\n",
    "kernel[1,1]=2\n",
    "dst = cv2.filter2D(img,-1,kernel)\n",
    "# Забавно, что при повторном применении этого Ядра картинка покрывается шумом! \n",
    "for i in range(3):\n",
    "    dst = cv2.filter2D(dst,-1,kernel)\n",
    "    \n",
    "# Можно почистить картинку от шума \n",
    "dst = cv2.GaussianBlur(dst,(5,5),0)\n",
    "\n",
    "kernel1 = np.array([[-1,-1,-1],[0,0,0],[1,1,1]],np.float32)\n",
    "kernel2 = kernel1.T\n",
    "\n",
    "dst1 = cv2.filter2D(dst,-1,kernel1)\n",
    "dst2 = cv2.filter2D(dst,-1,kernel2)\n",
    "gr2 = cv2.add(dst1,dst2)\n",
    "\n",
    "plt.subplot(131),plt.imshow(img),plt.title('Original')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(132),plt.imshow(dst),plt.title('Chetkaya')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(133),plt.imshow(gr2),plt.title('Gran')\n",
    "plt.xticks([]), plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "\n",
    "plt.subplot(121),plt.imshow(gr1),plt.title('Ne chetkaya')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(gr2),plt.title('Chetkaya')\n",
    "plt.xticks([]), plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вроде бы граница получилась более чёткой. Внутри пакета есть своя функция для выделения границы. Он работает более агрессивно нежели наше ядро."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "\n",
    "kernel1 = np.array([[-1,-1,-1],[0,0,0],[1,1,1]],np.float32)\n",
    "kernel2 = kernel1.T\n",
    "\n",
    "dst1 = cv2.filter2D(img,-1,kernel1)\n",
    "dst2 = cv2.filter2D(img,-1,kernel2)\n",
    "my_gr = cv2.add(dst1,dst2)\n",
    "\n",
    "# Пакетная функция:\n",
    "its_gr = cv2.Canny(img,100,200)\n",
    "\n",
    "plt.subplot(121),plt.imshow(my_gr),plt.title('Our kernel')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(its_gr,cmap='gray'),plt.title('Package kernel')\n",
    "plt.xticks([]), plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вообще, ядро поиска границы задаёт градиент картики по диагонали и градиент по вертикали. Можно побаловаться с более крутыми градиентами, в том числе диагональными.\n",
    "\n",
    "$$ \\begin{pmatrix}\n",
    "0 & 1 & 2  \\\\\n",
    "-1 & 0 & 1 \\\\         \n",
    "-2 & -1 & 0 \n",
    "\\end{pmatrix} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "\n",
    "img = cv2.imread('girl.png',0)\n",
    "img = cv2.cvtColor(img,cv2.COLOR_BAYER_BG2BGR) # Сделаем картинку серой\n",
    "\n",
    "kernel1 = 3*np.array([[0,1,2],[-1,0,1],[-2,-1,0]],np.float32)\n",
    "dst1 = cv2.filter2D(img,-1,kernel1)\n",
    "\n",
    "kernel2 = 3*np.array([[2,1,0],[1,0,-1],[0,-1,-2]],np.float32)\n",
    "dst2 = cv2.filter2D(img,-1,kernel2)\n",
    "\n",
    "plt.subplot(131),plt.imshow(img,),plt.title('Original')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(132),plt.imshow(dst1),plt.title('Averaging')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(133),plt.imshow(dst2),plt.title('Averaging')\n",
    "plt.xticks([]), plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "\n",
    "img = cv2.imread('detal.png',0)\n",
    "img = cv2.cvtColor(img,cv2.COLOR_BAYER_BG2BGR) # Сделаем картинку серой\n",
    "\n",
    "kernel1 = 3*np.array([[0,1,2],[-1,0,1],[-2,-1,0]],np.float32)\n",
    "dst1 = cv2.filter2D(img,-1,kernel1)\n",
    "\n",
    "kernel2 = 3*np.array([[2,1,0],[1,0,-1],[0,-1,-2]],np.float32)\n",
    "dst2 = cv2.filter2D(img,-1,kernel2)\n",
    "\n",
    "plt.subplot(131),plt.imshow(img,),plt.title('Original')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(132),plt.imshow(dst1),plt.title('Averaging')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(133),plt.imshow(dst2),plt.title('Averaging')\n",
    "plt.xticks([]), plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как вы уже догадались, можно придумать фильры не только для поиска границ, но и для поиска других различных закономерностей, которые есть на картинке. \n",
    "\n",
    "Представим себе на секунду славный дивный мир, в котором бывают картинки только двух типов: с прямыми слэшами и с обратными (/ \\). При этом, эти слэши могут быть нарисованы на картинке где угодно. Пусть у нас есть две картинки. На одной из них слэш нарисован внизу справа, на второй сверху слева. Пройдёмся по нашим картинкам специальным ядром, которое ищет обратные слэши. После свёртки, мы получим на выходе две уменьшившиеся в размерах картинки, в каждой из которых будет фигурировать цифра два, как раз отвечающая за найденный обратный слэш.\n",
    "\n",
    "<img align=\"center\" src=\"photo_1.png\" height=\"500\" width=\"500\"> \n",
    "\n",
    "Если точно такое же ядро натравить на картинку без обратного слэша, оно не выдаст нам на выход никакой двойки. \n",
    "\n",
    "<img align=\"center\" src=\"photo_2.png\" height=\"600\" width=\"600\"> \n",
    "\n",
    "Получаем простейший классификатор картинок с слэшами. \n",
    "\n",
    "1. Проходимся по картинке ядром. \n",
    "2. Находим в итоговой матрице максимальный элемент.\n",
    "3. Если это двойка, на картинке изображён слэш. Если это единица, на картинке обратный слэш.\n",
    "\n",
    "Обратите внимание, что работа этого классификатора не зависит от того, где именно на картинке находится слэш. Именно так свёрточные нейронные сети и работают с картинками. Конечно же, в реальности закономерности на картинках на порядок сложнее. При этом, мы даже не знаем какими именно могут быть эти закономерности. Для того, чтобы их искать, в нейронную сетку добавляются ядра с неспецифицированными параметрами.\n",
    "\n",
    "$$ \\begin{pmatrix}\n",
    "w_1 & w_2 & w_3  \\\\\n",
    "w_4 & w_5 & w_6 \\\\         \n",
    "w_7 & w_8 & w_9 \n",
    "\\end{pmatrix} $$\n",
    "\n",
    "Слои, на которых находятся эти ядра называются свёрточными. Параметры подбираются в ходе обучения нейронной сети по реальным данным и отражают в себе какие-то закономерности, найденные во время обучения на картинках. Представим, что наша нейронная сеть должна уметь распознавать лица. Добавим в неё несколько свёрточных слоёв. \n",
    "\n",
    "Первый слой будет находить простейшие элементы, такие как слэши, прямые чёрточки и извилистые чёрточки. Второй слой будет конструировать из элементов, найденных на первом слое, ещё более сложные штуки. В данном случае окружности и крестики. Третий слой будет конструировать из объектов, найденных на втором слое ещё более сложные объекты. Таким образом, мы, слой за слоем, будем собирать всё более и более сложные объекты до тех пор, пока не дойдём до лица. \n",
    "\n",
    "<img align=\"center\" src=\"photo_3.png\" height=\"600\" width=\"600\"> \n",
    "\n",
    "Обычно закономерности, которые находит свёрточная сеть сложно интерпретируемы. Тем не менее, мы можем забрать те закономерности, которые нашла нейросетка и использовать их в качестве регрессоров в какой-то более интерпретируемой модели."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
