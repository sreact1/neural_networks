{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как научить компьютер читать?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Подготовка и обучение\n",
    "\n",
    "Будем обучать w2v модель на википедии. К счастью, в её случае для всех языков предусмотрена система дампов. С [удобной странчки](https://dumps.wikimedia.org) можно скачать текущую полную версию википедийного текста на любом языке. Например, [на русском.](https://dumps.wikimedia.org/ruwiki/).\n",
    "\n",
    "Для обучения модели будем использовать библиотеку `gensim`. В ней уже есть удобный модуль доя работы с википедийными дампами, а также готовая хорошая реализация w2v-сетки. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/fulyankin/Yandex.Disk.localized/Научные проекты/w2v/ruwiki-20180320-pages-articles-multistream.xml.bz2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora.wikicorpus import WikiCorpus\n",
    "\n",
    "# для доступа к текстам мы будем пользоваться генератором wiki.get_texts()\n",
    "wiki = WikiCorpus(path, dictionary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Корпус википедии, оказавшийся в наших руках уже прошёл очистку от мусора и был токенезирован. Посмотрим на первые $40$ слов самой первой её статьи. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['литва', 'официальное', 'название', 'лито', 'вская', 'респу', 'блика', 'государство', 'расположенное', 'северной', 'европе', 'одна', 'из', 'стран', 'балтии', 'столица', 'страны', 'вильнюс', 'площадь', 'км²', 'протяжённость', 'севера', 'на', 'юг', 'км', 'запада', 'на', 'восток', 'км', 'население', 'составляет', 'человек', 'по', 'этим', 'показателям', 'является', 'крупнейшим', 'прибалтийским', 'государством', 'имеет']\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for text in wiki.get_texts( ):\n",
    "    i+=1\n",
    "    if i == 2:\n",
    "        break\n",
    "    else:\n",
    "        print(text[:40])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем выделить в тексте основные биграммы. Будем рассматривать их в дальнейшем как цельные токены. Существует целый ряд алгоритмов, занимающихся этим. Обычно все они сводятся к поиску вероятностей совместного появления двух слов в тексте. \n",
    "\n",
    "Код ниже для большого корпуса текстов будет работать довольно долго, но зато на выходе мы получим словарь биграмм, который мы сможем впоследствии применять к потоку текстов командой `bigram_transformer`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34min 40s, sys: 1min 32s, total: 36min 13s\n",
      "Wall time: 44min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "\n",
    "# хочется посмотреть на самые частые биграммы и использовать их при обучении как токены\n",
    "bigram = Phrases(wiki.get_texts())\n",
    "bigram_transformer = Phraser(bigram)\n",
    "\n",
    "# генератор текстов с биграммами\n",
    "def text_generator_bigram( ):\n",
    "    for text in wiki.get_texts( ):\n",
    "        yield bigram_transformer[[word for word in text]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим что нам будет выдавать такой генератор на примере первой статьи с википедии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['литва', 'официальное', 'название', 'лито_вская', 'респу_блика', 'государство', 'расположенное', 'северной', 'европе', 'одна', 'из', 'стран_балтии', 'столица', 'страны', 'вильнюс', 'площадь_км²', 'протяжённость', 'севера', 'на', 'юг']\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for item in text_generator_bigram( ):\n",
    "    i +=1 \n",
    "    if i == 2:\n",
    "        break\n",
    "    else:\n",
    "        print(item[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По аналогии можно соорудить код для поиска самых частых триграмм. Например, триграммой будет словосочетание \"по моему мнению\" или \"вторая мировая война\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 7min 39s, sys: 2min 25s, total: 1h 10min 4s\n",
      "Wall time: 2h 10min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trigram = Phrases(text_generator_bigram())\n",
    "trigram_transformer = Phraser(trigram)\n",
    "\n",
    "def text_generator_trigram():\n",
    "    for text in wiki.get_texts():\n",
    "        yield trigram_transformer[bigram_transformer[[word for word in text]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['литва', 'официальное_название', 'лито_вская', 'респу_блика_государство', 'расположенное', 'северной', 'европе', 'одна', 'из', 'стран_балтии', 'столица', 'страны', 'вильнюс', 'площадь_км²', 'протяжённость_севера', 'на', 'юг', 'км', 'запада', 'на']\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for item in text_generator_trigram( ):\n",
    "    i +=1 \n",
    "    if i == 2:\n",
    "        break\n",
    "    else:\n",
    "        print(item[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На этом давайте закончим нашу подготовку и попробуем собрать и обучить модель. Конечно же учиться она будет довольно долго. Не факт, что на слабом компьютере она вообще выучится. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 7min 3s, sys: 1min 57s, total: 1h 9min\n",
      "Wall time: 1h 14min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "# теперь сама модель\n",
    "# size - размерность векторов \n",
    "# window - ширина окна контеста\n",
    "# min_count - если слово встречается реже, для него не учим модель\n",
    "model = Word2Vec(size=300, window=7, min_count=10, workers=4)\n",
    "\n",
    "# строительство словаря, чтобы обучение шло быстрее\n",
    "model.build_vocab(text_generator_trigram())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 43min 22s, sys: 5min 24s, total: 1h 48min 47s\n",
      "Wall time: 1h 25min 34s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "323437961"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# обучение модели \n",
    "model.train(text_generator_trigram(), total_examples=model.corpus_count, epochs=model.iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обученную модель можно сохранить. Процесс её обучения довольно трудоёмок, не очень хочется его повторять по несколько раз."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохраним обученную модель\n",
    "model.save('wiki_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По аналогии сохраним создатель триграмм. Он тоже учился довольно долго, а нам хотелось бы в дальнейшем его переиспользовать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_transformer.save('wiki_trigramm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Игрушечки\n",
    "\n",
    "Попробуем поисследовать линейные соотношения между векторами в получившемся семантическом пространстве. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "# подгрузим обученную модель, если вдруг мы сбросили скрипт\n",
    "# model = gensim.models.Word2Vec.load('wiki_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала посмотрим как выглядит слово в получившемся пространстве."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.4187494 ,  1.3197291 ,  0.5561069 , -2.674209  , -0.39070314,\n",
       "       -1.7381759 ,  2.4423337 ,  1.1509248 ,  0.49805412,  1.0481958 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# вектор слова\n",
    "model.wv['король'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно посмотреть насколько слова похожи между собой. Эта похожесть считается с помощью косинусной метрики."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5731954174129064"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# похожесть между словами\n",
    "model.wv.similarity('мужчина', 'женщина')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7277190300871142"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('чашка', 'стакан')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14659733109020415"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('грядка', 'станок')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем провернуть первое уравнение. \n",
    "\n",
    "$$ Король + Женшина - Мужчина = \\quad ???$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('королева', 0.6225535869598389),\n",
       " ('империя', 0.5604485869407654),\n",
       " ('принцесса', 0.5506317615509033),\n",
       " ('императрица', 0.5310197472572327),\n",
       " ('король_ок_ок', 0.5229284763336182),\n",
       " ('правительница', 0.5220396518707275),\n",
       " ('королевская_семья', 0.5136938095092773),\n",
       " ('герцогиня', 0.5069049596786499),\n",
       " ('великий_король', 0.5020265579223633),\n",
       " ('инквизиция', 0.4958014190196991)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['женщина', 'король'], negative=['мужчина'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ Москва + Франция - Россия = \\quad ???$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('париж', 0.5632048845291138),\n",
       " ('жан', 0.5306471586227417),\n",
       " ('жак', 0.5089118480682373),\n",
       " ('пьер', 0.5062865018844604),\n",
       " ('французский', 0.5051255822181702),\n",
       " ('шарль', 0.503093957901001),\n",
       " ('марсель', 0.49368593096733093),\n",
       " ('париже', 0.4840250611305237),\n",
       " ('анри', 0.4825429916381836),\n",
       " ('франсуа', 0.47708338499069214)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['москва', 'франция'], negative=['россия'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ Математик + Женшина - Мужчина = \\quad ???$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('филолог', 0.6791591048240662),\n",
       " ('получившая_степень_доктора', 0.665369987487793),\n",
       " ('лингвист', 0.6601260900497437),\n",
       " ('доктор_философии', 0.6564381122589111),\n",
       " ('доктор_филологических_наук', 0.6553531885147095),\n",
       " ('переводчица', 0.6419261693954468),\n",
       " ('поэтесса', 0.639553964138031),\n",
       " ('поэтесса_писательница', 0.6373691558837891),\n",
       " ('доктор_философских_наук', 0.6361896991729736),\n",
       " ('педагог_профессор', 0.6341406106948853)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['математик', 'женщина'], negative=['мужчина'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ Ваше \\mbox{ } уравнение $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(positive=[' ', ' '], negative=[' '])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(positive=[' ', ' '], negative=[' '])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(positive=[' ', ' '], negative=[' '])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте попробуем просто посмотреть на самые близкие к каким-то выражениям слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('первая_мировая_война', 0.8385074138641357),\n",
       " ('корейская_война', 0.71861332654953),\n",
       " ('холодная_война', 0.6932598948478699),\n",
       " ('третий_рейх', 0.6707549095153809),\n",
       " ('люфтваффе', 0.6602753400802612),\n",
       " ('межвоенный_период', 0.6552859544754028),\n",
       " ('третьего_рейха', 0.6543014049530029),\n",
       " ('война_судного_дня', 0.6508054137229919),\n",
       " ('семилетняя_война', 0.6481649875640869),\n",
       " ('первой_мировой', 0.6462584733963013)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('вторая_мировая_война')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('mail_ru', 0.8583327531814575),\n",
       " ('яндекса', 0.8314518928527832),\n",
       " ('google', 0.8099757432937622),\n",
       " ('сети_интернет', 0.8059083223342896),\n",
       " ('веб', 0.7968020439147949),\n",
       " ('сервис', 0.7944517731666565),\n",
       " ('хостинг', 0.7870197296142578),\n",
       " ('yandex_ru', 0.7709559798240662),\n",
       " ('открытый_доступ', 0.7646337747573853),\n",
       " ('аккаунт', 0.7615125179290771)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('яндекс')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('высшей_школы_экономики', 0.895513653755188),\n",
       " ('высшая_школа_экономики', 0.8587247729301453),\n",
       " ('российского_гуманитарного_университета', 0.8499684929847717),\n",
       " ('вшэ', 0.8479135036468506),\n",
       " ('ранхигс', 0.8308689594268799),\n",
       " ('мпгу', 0.830706000328064),\n",
       " ('гу_вшэ', 0.8254082798957825),\n",
       " ('мгимо', 0.8184138536453247),\n",
       " ('спбгу', 0.8165745139122009),\n",
       " ('мгпу', 0.8162704110145569)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('ниу_вшэ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('аристотеля', 0.8488722443580627),\n",
       " ('стоиков', 0.8021489381790161),\n",
       " ('гегель', 0.7997527122497559),\n",
       " ('ориген', 0.7984192371368408),\n",
       " ('своих_трудах', 0.7923400402069092),\n",
       " ('лейбниц', 0.789554238319397),\n",
       " ('плутарх', 0.7830368280410767),\n",
       " ('цицерон', 0.7817286252975464),\n",
       " ('маймонид', 0.7758834362030029),\n",
       " ('тацит', 0.7727030515670776)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('аристотель')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('король_шут', 0.8701559901237488),\n",
       " ('агата_кристи', 0.8659921288490295),\n",
       " ('сплин', 0.8545758724212646),\n",
       " ('весёлые_ребята', 0.8407142162322998),\n",
       " ('чайф', 0.8382944464683533),\n",
       " ('ногу_свело', 0.8371785879135132),\n",
       " ('ночные_снайперы', 0.8325160145759583),\n",
       " ('наив', 0.8310174942016602),\n",
       " ('валерий_леонтьев', 0.8306418657302856),\n",
       " ('андрей_макаревич', 0.8283897638320923)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('машина_времени')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посмотрим на то, что интересует вас!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нужно понимать, что в выборке, на основе которой вы обучали модель могут быть различные \"артефакты\". Например, если мы обучались на корпусе новостей, мы можем неожиданно обнаружить, что к Индонезии очень близко землятрясение. Почему? Да просто потому что в корпусе все статьи, связанные с Индонезией упоминали недавнее землятрясение. С такми артефактами приходится бороться и переодически модель приходится переобучать. В ситуации выше машина времени является подобным артефактом модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Полезные ссылки \n",
    "\n",
    "* [Предобученная w2v для английского языка](https://code.google.com/archive/p/word2vec)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
