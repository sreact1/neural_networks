# Введение в нейросетки, сезон 2018

## Интересные ссылки

* [Учим нейросеть](https://playground.tensorflow.org) не отходя от браузера!


## Логи семинаров

### Семинар 6

* [Презенташка с разными архитектурами](https://github.com/FUlyankin/neural_networks/blob/master/HSE_2018/sem_4/nn_slides_6.pdf)

### Семинар 5

* [Хочу всё и сразу!](https://github.com/FUlyankin/neural_networks/blob/master/HSE_2018/sem_5.zip)
* [Тетрадка про TensorFlow](http://nbviewer.jupyter.org/github/FUlyankin/neural_networks/blob/master/HSE_2018/sem_5/5.1%20introduction_tensorflow.ipynb)
* [Тетрадка про GANы](http://nbviewer.jupyter.org/github/FUlyankin/neural_networks/blob/master/HSE_2018/sem_5/5.2%20GAN.ipynb)

### Семинар 4

* [Хочу всё и сразу, кроме данных. Не хочу данные.](https://github.com/FUlyankin/neural_networks/blob/master/HSE_2018/sem_4.zip)
* [Дамп википедии.](https://yadi.sk/d/Ddcl3nAiDO2CKQ)
* [w2v, которую мы предобучили на википедии](https://yadi.sk/d/XHQLpVZSc88aUw).

* [Слайды](https://github.com/FUlyankin/neural_networks/blob/master/HSE_2018/sem_4/nn_slides_4.pdf)
* [Как научить компьютер читать](http://nbviewer.jupyter.org/github/FUlyankin/neural_networks/blob/master/HSE_2018/sem_4/4.1%20wikipedia_w2v.ipynb)
* [Немного LSTM сеток](http://nbviewer.jupyter.org/github/FUlyankin/neural_networks/blob/master/HSE_2018/sem_4/4.2%20LSTM_sentment_w2v.ipynb)


### Семинар 3

* [Хочу всё и сразу!](https://github.com/FUlyankin/neural_networks/blob/master/HSE_2018/sem_3.zip)
* Добавить ссылку на датасет с цветами

### Семинар 2

* [Презентация](https://github.com/FUlyankin/neural_networks/blob/master/HSE_2018/sem_2/nn_slides_2.pdf)
* [Тетрадка](http://nbviewer.jupyter.org/github/FUlyankin/neural_networks/blob/master/HSE_2018/sem_2/1.%20Convolution.ipynb)  с примерами ядер и картинками.  [Дайнерис](https://github.com/FUlyankin/neural_networks/blob/master/HSE_2018/sem_2/denny.jpg), [туманный лес](https://github.com/FUlyankin/neural_networks/blob/master/HSE_2018/sem_2/forest.jpg), [цветок жизни](https://github.com/FUlyankin/neural_networks/blob/master/HSE_2018/sem_2/girl.png) [деталь](https://github.com/FUlyankin/neural_networks/blob/master/HSE_2018/sem_2/detal.PNG)
* [Тетрадка с нашей первой CNN](http://nbviewer.jupyter.org/github/FUlyankin/neural_networks/blob/master/HSE_2018/sem_2/2.%20CNN_MNIST.ipynb)
* [Шпаргалка по Keras](https://github.com/FUlyankin/neural_networks/blob/master/HSE_2018/sem_2/Keras_Cheat_Sheet_Python.pdf)

* [Решение задания](http://nbviewer.jupyter.org/github/FUlyankin/neural_networks/blob/master/HSE_2018/sem_1/hw1_part1_gradient_solution.ipynb) на градиентный спуск
* [Новое задание](http://nbviewer.jupyter.org/github/FUlyankin/neural_networks/blob/master/HSE_2018/sem_2/3.%20Keras_CNN.ipynb) на CIFAR10 и data augmentation


### Семинар 1

* [Презентация](https://github.com/FUlyankin/neural_networks/blob/master/HSE_2018/sem_1/slides.pdf)
* [Тетрадка](http://nbviewer.jupyter.org/github/FUlyankin/neural_networks/blob/master/HSE_2018/sem_1/Keras_classification_intro.ipynb) с нашей первой нейросеткой в Keras! Данные: [признаки](https://github.com/FUlyankin/neural_networks/blob/master/HSE_2018/sem_1/X_cat.csv) и [ответы.](https://github.com/FUlyankin/neural_networks/blob/master/HSE_2018/sem_1/y_cat.csv) Данные позаимствованы с [соревнования на Kaggle.](https://www.kaggle.com/c/shelter-animal-outcomes)
* [Блокнот](http://nbviewer.jupyter.org/github/FUlyankin/neural_networks/blob/master/HSE_2018/sem_1/original_cats/cats_data_prep.ipynb) с предобработкой данных, на который мы НЕ смотрели на паре, но который меня попросили выложить.
* [Задание на 50 оттенков градиентного спуска](http://nbviewer.jupyter.org/github/FUlyankin/neural_networks/blob/master/HSE_2018/sem_1/hw1_part1_gradient.ipynb)


## Текущий план семинаров

Можно внести корективы, если вам будет угодно :)

1. Разновидности градиентного спуска. История нейронных сетей, первые перцептроны, алгоритм обратного распространения ошибки. Собираем свою первую нейросетку в Keras для решения задачи классификации.
2. Свёртка, свёрточный нейросетки. Современные свёрточные архитектуры.
3. Автокодировщики. Трюки, используемые при обучении нейронных сеток: инициализация весов, функции активации, Dropout, BatchNorm.
4. Говорим про рекурентные нейросетки, учим компьютер работать с текстами, говорим про распределённое представление слов и w2v на википедии
5. Осваиваем Tensorflow,
6. Краткий обзор современных нейросетевых архитектур (модели с вниманием, состязательные сети, о перспективах нейробайесовских методов).
